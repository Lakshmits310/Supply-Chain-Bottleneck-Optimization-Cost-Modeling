{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec480631",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'supply_chain_db.db' created and data loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# 1. Load the CLEAN data we saved in the previous step\n",
    "df_clean = pd.read_csv('../02_Processed_Data/logistics_transactions_clean.csv')\n",
    "\n",
    "# 2. Create a connection to a local database\n",
    "conn = sqlite3.connect('supply_chain_db.db')\n",
    "\n",
    "# 3. Push the dataframe into the database as a table named 'logistics'\n",
    "df_clean.to_sql('logistics', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Database 'supply_chain_db.db' created and data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8602b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bottleneck_Factor            Segment  Total_Deliveries  Avg_OCI\n",
      "0         Traffic_Level            8.68447               1.0  1416.60\n",
      "1         Traffic_Level           2.807849               1.0  1416.11\n",
      "2         Traffic_Level           0.962598               1.0  1416.03\n",
      "3         Traffic_Level           9.988406               1.0  1414.95\n",
      "4         Traffic_Level           6.614813               1.0  1414.72\n",
      "...                 ...                ...               ...      ...\n",
      "26119        Risk_Level           2.888323               NaN   100.00\n",
      "26120        Risk_Level           1.522404               NaN   100.00\n",
      "26121        Risk_Level            0.62645               NaN   100.00\n",
      "26122      Loading_Time   Low_Loading_Time            4181.0   568.09\n",
      "26123      Loading_Time  High_Loading_Time            8880.0   560.08\n",
      "\n",
      "[26124 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "WITH Traffic_Analysis AS (\n",
    "    -- Analyze Cost Impact by Traffic Level (0-10)\n",
    "    SELECT\n",
    "        traffic_congestion_level,\n",
    "        COUNT(T1.traffic_congestion_level) AS Total_Deliveries,\n",
    "        ROUND(AVG(T1.Operational_Cost_Impact), 2) AS Avg_OCI\n",
    "    FROM logistics T1\n",
    "    GROUP BY traffic_congestion_level\n",
    "    ORDER BY Avg_OCI DESC\n",
    "),\n",
    "\n",
    "Risk_Analysis AS (\n",
    "    -- Analyze Cost Impact by Route Risk Level (0-10)\n",
    "    SELECT\n",
    "        route_risk_level,\n",
    "        ROUND(AVG(T2.Operational_Cost_Impact), 2) AS Avg_OCI\n",
    "    FROM logistics T2\n",
    "    GROUP BY route_risk_level\n",
    "    ORDER BY Avg_OCI DESC\n",
    "),\n",
    "\n",
    "Warehouse_Analysis AS (\n",
    "    -- Analyze Cost Impact by Loading/Unloading Time (1-hour cutoff is a business assumption)\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN loading_unloading_time > 1.0 THEN 'High_Loading_Time'\n",
    "            ELSE 'Low_Loading_Time'\n",
    "        END AS Loading_Efficiency_Bucket,\n",
    "        COUNT(*) AS Total_Deliveries,\n",
    "        ROUND(AVG(T3.Operational_Cost_Impact), 2) AS Avg_OCI\n",
    "    FROM logistics T3\n",
    "    GROUP BY Loading_Efficiency_Bucket\n",
    "    ORDER BY Avg_OCI DESC\n",
    ")\n",
    "\n",
    "-- UNION the results into one table for easy review in the notebook\n",
    "SELECT 'Traffic_Level' AS Bottleneck_Factor, traffic_congestion_level AS Segment, Total_Deliveries, Avg_OCI FROM Traffic_Analysis\n",
    "UNION ALL\n",
    "SELECT 'Risk_Level' AS Bottleneck_Factor, route_risk_level AS Segment, NULL AS Total_Deliveries, Avg_OCI FROM Risk_Analysis\n",
    "UNION ALL\n",
    "SELECT 'Loading_Time' AS Bottleneck_Factor, Loading_Efficiency_Bucket AS Segment, Total_Deliveries, Avg_OCI FROM Warehouse_Analysis;\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and save the result into a dataframe\n",
    "bottleneck_data = pd.read_sql(query, conn)\n",
    "\n",
    "# Show the full result\n",
    "print(bottleneck_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
